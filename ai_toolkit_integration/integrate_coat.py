"""
å°†COATé›†æˆåˆ°ai-toolkitçš„è„šæœ¬
ä¿®æ”¹ai-toolkitçš„è®­ç»ƒæµç¨‹ä»¥æ”¯æŒCOATä¼˜åŒ–

ä½¿ç”¨æ–¹æ³•:
1. å°†æ­¤æ–‡ä»¶æ”¾åœ¨ai-toolkitç›®å½•ä¸‹
2. è¿è¡Œ: python integrate_coat.py
3. ä½¿ç”¨coat_config.yamlè¿›è¡Œè®­ç»ƒ
"""

import os
import sys
from pathlib import Path


def patch_ai_toolkit_optimizer():
    """
    ä¿®è¡¥ai-toolkitçš„ä¼˜åŒ–å™¨åˆ›å»ºé€»è¾‘
    æ·»åŠ å¯¹COAT FP8ä¼˜åŒ–å™¨çš„æ”¯æŒ
    """
    
    # å‡è®¾ai-toolkitçš„ä¼˜åŒ–å™¨åœ¨ toolkit/optimizers.py æˆ–ç±»ä¼¼ä½ç½®
    optimizer_patch = '''
# COAT FP8ä¼˜åŒ–å™¨é›†æˆ
import sys
from pathlib import Path

# æ·»åŠ COATè·¯å¾„
coat_path = Path(__file__).parent.parent / "coat_implementation"
sys.path.insert(0, str(coat_path))

from coat_implementation import FP8AdamW, FP8QuantizationConfig

def create_optimizer(optimizer_type, parameters, lr, **kwargs):
    """åˆ›å»ºä¼˜åŒ–å™¨ï¼Œæ”¯æŒCOAT FP8ä¼˜åŒ–å™¨"""
    
    if optimizer_type == "coat_fp8_adamw":
        # ä»kwargsæå–COATé…ç½®
        fp8_config = FP8QuantizationConfig(
            use_fp8_m1=kwargs.get('use_fp8_m1', True),
            use_fp8_m2=kwargs.get('use_fp8_m2', True),
            m1_format=kwargs.get('m1_format', 'e4m3'),
            m2_format=kwargs.get('m2_format', 'e4m3'),
            block_size=kwargs.get('block_size', 128),
            use_dynamic_range_expansion=kwargs.get('use_dynamic_range_expansion', True)
        )
        
        return FP8AdamW(
            parameters,
            lr=lr,
            betas=kwargs.get('betas', (0.9, 0.999)),
            eps=kwargs.get('eps', 1e-8),
            weight_decay=kwargs.get('weight_decay', 0.01),
            fp8_config=fp8_config
        )
    
    # åŸæœ‰ä¼˜åŒ–å™¨é€»è¾‘...
    elif optimizer_type == "adamw":
        import torch
        return torch.optim.AdamW(parameters, lr=lr, **kwargs)
    else:
        raise ValueError(f"Unknown optimizer type: {optimizer_type}")
'''
    
    return optimizer_patch


def patch_ai_toolkit_trainer():
    """
    ä¿®è¡¥ai-toolkitçš„è®­ç»ƒå™¨
    æ·»åŠ FP8æ¿€æ´»é‡åŒ–æ”¯æŒ
    """
    
    trainer_patch = '''
# COAT FP8æ¿€æ´»é‡åŒ–é›†æˆ
import sys
from pathlib import Path

coat_path = Path(__file__).parent.parent / "coat_implementation"
sys.path.insert(0, str(coat_path))

from coat_implementation import replace_linear_with_fp8, FP8PrecisionFlow

class COATEnhancedTrainer:
    """å¢å¼ºçš„è®­ç»ƒå™¨ï¼Œé›†æˆCOATä¼˜åŒ–"""
    
    def __init__(self, config):
        self.config = config
        self.coat_enabled = config.get('coat', {}).get('enabled', False)
        self.precision_flow = None
        
        if self.coat_enabled:
            print("ğŸš€ COATä¼˜åŒ–å·²å¯ç”¨!")
            self.precision_flow = FP8PrecisionFlow()
    
    def prepare_model(self, model):
        """å‡†å¤‡æ¨¡å‹"""
        if self.coat_enabled:
            activation_config = self.config.get('coat', {}).get('activation', {})
            if activation_config.get('use_fp8', False):
                print("ğŸ”„ åº”ç”¨FP8æ¿€æ´»é‡åŒ–...")
                model = replace_linear_with_fp8(model, recursive=True)
        
        return model
    
    def training_step(self, model, batch, optimizer, step):
        """è®­ç»ƒæ­¥éª¤"""
        
        # è®°å½•å†…å­˜
        if self.coat_enabled and self.config.get('coat', {}).get('memory', {}).get('log_memory_stats', False):
            self._log_memory(step, "before_forward")
        
        # å‰å‘ä¼ æ’­
        outputs = model(**batch)
        loss = outputs.loss if hasattr(outputs, 'loss') else outputs
        
        if self.coat_enabled:
            self._log_memory(step, "after_forward")
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        
        if self.coat_enabled:
            self._log_memory(step, "after_backward")
        
        # æ¢¯åº¦è£å‰ª
        if 'gradient_clipping' in self.config.get('train', {}):
            torch.nn.utils.clip_grad_norm_(
                model.parameters(), 
                self.config['train']['gradient_clipping']
            )
        
        # ä¼˜åŒ–å™¨æ­¥è¿›
        optimizer.step()
        
        if self.coat_enabled:
            self._log_memory(step, "after_optimizer_step")
        
        return {'loss': loss.item()}
    
    def _log_memory(self, step, phase):
        """è®°å½•å†…å­˜ä½¿ç”¨"""
        import torch
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            print(f"ğŸ“Š [{phase}] Step {step}: Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB")
'''
    
    return trainer_patch


def create_integration_guide():
    """åˆ›å»ºé›†æˆæŒ‡å—"""
    
    guide = """
# COAT + ai-toolkit é›†æˆæŒ‡å—

## 1. å®‰è£…ä¾èµ–

```bash
pip install torch>=2.1.0  # éœ€è¦æ”¯æŒFP8çš„PyTorchç‰ˆæœ¬
pip install transformers diffusers accelerate
```

## 2. ç›®å½•ç»“æ„

ç¡®ä¿ç›®å½•ç»“æ„å¦‚ä¸‹:
```
flux lora/
â”œâ”€â”€ coat_implementation/          # COATå®ç°ä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ fp8_optimizer.py
â”‚   â”œâ”€â”€ fp8_activation.py
â”‚   â””â”€â”€ coat_trainer.py
â”œâ”€â”€ ai-toolkit/                   # ai-toolkitä»“åº“
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ai_toolkit_integration/       # é›†æˆä»£ç 
â”‚   â”œâ”€â”€ coat_config.yaml
â”‚   â””â”€â”€ integrate_coat.py
â””â”€â”€ datasets/
    â””â”€â”€ clothing/                 # æœè£…å›¾ç‰‡æ•°æ®é›†
        â”œâ”€â”€ image1.jpg
        â”œâ”€â”€ image1.txt
        â”œâ”€â”€ image2.jpg
        â”œâ”€â”€ image2.txt
        â””â”€â”€ ...
```

## 3. ä¿®æ”¹ai-toolkitä»£ç 

### æ–¹æ³•A: æ‰‹åŠ¨é›†æˆ (æ¨è)

#### 3.1 ä¿®æ”¹ä¼˜åŒ–å™¨åˆ›å»ºä»£ç 

åœ¨ `ai-toolkit/toolkit/optimizers.py` (æˆ–ç›¸åº”æ–‡ä»¶) ä¸­æ·»åŠ :

```python
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
import sys
from pathlib import Path
coat_path = Path(__file__).parent.parent.parent / "coat_implementation"
sys.path.insert(0, str(coat_path))

from coat_implementation import FP8AdamW, FP8QuantizationConfig

# åœ¨create_optimizerå‡½æ•°ä¸­æ·»åŠ 
def get_optimizer(config, parameters):
    optimizer_type = config.get('train', {}).get('optimizer', 'adamw')
    lr = config.get('train', {}).get('lr', 1e-4)
    
    if optimizer_type == "coat_fp8_adamw":
        coat_config = config.get('coat', {}).get('optimizer', {})
        fp8_config = FP8QuantizationConfig(
            use_fp8_m1=coat_config.get('use_fp8', True),
            use_fp8_m2=coat_config.get('use_fp8', True),
            m1_format=coat_config.get('m1_format', 'e4m3'),
            m2_format=coat_config.get('m2_format', 'e4m3'),
            block_size=coat_config.get('block_size', 128),
            use_dynamic_range_expansion=coat_config.get('use_dynamic_range_expansion', True)
        )
        
        return FP8AdamW(parameters, lr=lr, fp8_config=fp8_config)
    
    # åŸæœ‰é€»è¾‘...
```

#### 3.2 ä¿®æ”¹è®­ç»ƒå™¨ä»£ç 

åœ¨ `ai-toolkit/toolkit/trainer.py` (æˆ–ç›¸åº”æ–‡ä»¶) ä¸­:

```python
# å¯¼å…¥COATæ¨¡å—
from coat_implementation import replace_linear_with_fp8

class Trainer:
    def setup(self):
        # åœ¨æ¨¡å‹å‡†å¤‡é˜¶æ®µ
        if self.config.get('coat', {}).get('enabled', False):
            if self.config.get('coat', {}).get('activation', {}).get('use_fp8', False):
                print("ğŸ”„ åº”ç”¨COAT FP8æ¿€æ´»é‡åŒ–...")
                self.model = replace_linear_with_fp8(self.model)
```

### æ–¹æ³•B: ä½¿ç”¨Monkey Patching

åˆ›å»º `train_with_coat.py`:

```python
import sys
sys.path.insert(0, 'coat_implementation')

# å¯¼å…¥ai-toolkit
from ai_toolkit import train

# å¯¼å…¥COAT
from coat_implementation import COATTrainer, COATConfig

# Monkey patch ai-toolkitçš„è®­ç»ƒé€»è¾‘
original_create_optimizer = train.create_optimizer

def coat_create_optimizer(config, parameters):
    if config.get('train', {}).get('optimizer') == 'coat_fp8_adamw':
        coat_trainer = COATTrainer(COATConfig())
        return coat_trainer.create_optimizer(parameters, lr=config.get('train', {}).get('lr', 1e-4))
    return original_create_optimizer(config, parameters)

train.create_optimizer = coat_create_optimizer

# è¿è¡Œè®­ç»ƒ
if __name__ == "__main__":
    train.main()
```

## 4. å‡†å¤‡æ•°æ®é›†

### 4.1 æ•°æ®é›†æ ¼å¼

æœè£…å›¾ç‰‡æ•°æ®é›†åº”è¯¥åŒ…å«:
- å›¾ç‰‡æ–‡ä»¶: `.jpg`, `.jpeg`, `.png`
- æ ‡æ³¨æ–‡ä»¶: ä¸å›¾ç‰‡åŒåçš„ `.txt` æ–‡ä»¶

ç¤ºä¾‹:
```
datasets/clothing/
â”œâ”€â”€ dress_001.jpg
â”œâ”€â”€ dress_001.txt      # å†…å®¹: "a beautiful red [trigger] dress with floral patterns"
â”œâ”€â”€ jacket_002.jpg
â”œâ”€â”€ jacket_002.txt     # å†…å®¹: "a leather [trigger] jacket, black color"
â””â”€â”€ ...
```

### 4.2 æ ‡æ³¨å»ºè®®

- ä½¿ç”¨æè¿°æ€§æ ‡æ³¨: "a [trigger] dress with floral patterns, high quality"
- åŒ…å«è§¦å‘è¯: `[trigger]` ä¼šè¢«é…ç½®ä¸­çš„ `trigger_word` æ›¿æ¢
- æè¿°é¢œè‰²ã€æè´¨ã€é£æ ¼ç­‰ç»†èŠ‚

## 5. è¿è¡Œè®­ç»ƒ

```bash
cd ai-toolkit
python run.py ../ai_toolkit_integration/coat_config.yaml
```

æˆ–ä½¿ç”¨è‡ªå®šä¹‰è„šæœ¬:
```bash
python train_with_coat.py --config ../ai_toolkit_integration/coat_config.yaml
```

## 6. æ€§èƒ½å¯¹æ¯”

COATé¢„æœŸæ”¶ç›Š:
- âœ… å†…å­˜ä½¿ç”¨å‡å°‘ ~1.54x
- âœ… è®­ç»ƒé€Ÿåº¦æå‡ ~1.43x
- âœ… å¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch size (æå‡åˆ°2-4å€)
- âœ… æ¨¡å‹ç²¾åº¦æ— æŸå¤±

### ç›‘æ§å†…å­˜ä½¿ç”¨

è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨æ‰“å°å†…å­˜ç»Ÿè®¡:
```
ğŸ“Š [before_forward] Step 100: Allocated: 8.23GB, Reserved: 10.50GB
ğŸ“Š [after_forward] Step 100: Allocated: 12.45GB, Reserved: 14.00GB
ğŸ“Š [after_backward] Step 100: Allocated: 10.67GB, Reserved: 14.00GB
ğŸ“Š [after_optimizer_step] Step 100: Allocated: 8.23GB, Reserved: 14.00GB
```

## 7. å¸¸è§é—®é¢˜

### Q: PyTorchä¸æ”¯æŒFP8æ€ä¹ˆåŠ?

A: ä»£ç ä¼šè‡ªåŠ¨é™çº§åˆ°bfloat16ã€‚è™½ç„¶å†…å­˜èŠ‚çœæ•ˆæœä¼šæ‰“æŠ˜æ‰£ï¼Œä½†ä»ç„¶å¯ä»¥è¿è¡Œã€‚å»ºè®®ä½¿ç”¨PyTorch 2.1+å’ŒCUDA 12+ã€‚

### Q: è®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡?

A: ç¡®ä¿:
1. ä½¿ç”¨æ”¯æŒFP8çš„GPU (å¦‚H100, L40S)
2. CUDAç‰ˆæœ¬ >= 12.0
3. batch_sizeè¶³å¤Ÿå¤§ä»¥åˆ©ç”¨å†…å­˜èŠ‚çœ

### Q: ç²¾åº¦æŸå¤±?

A: COATè®¾è®¡ä¸ºæ— æŸåŠ é€Ÿã€‚å¦‚æœè§‚å¯Ÿåˆ°ç²¾åº¦æŸå¤±ï¼Œå°è¯•:
1. è°ƒæ•´ `block_size` (é»˜è®¤128)
2. ä½¿ç”¨ `e5m2` æ ¼å¼ä»£æ›¿ `e4m3`
3. ç¦ç”¨åŠ¨æ€èŒƒå›´æ‰©å±• (ä¸æ¨è)

## 8. è¿›é˜¶é…ç½®

### åªè®­ç»ƒç‰¹å®šå±‚

```yaml
network:
  type: "lora"
  linear: 16
  linear_alpha: 16
  network_kwargs:
    only_if_contains:
      - "transformer.single_transformer_blocks.7.proj_out"
      - "transformer.single_transformer_blocks.20.proj_out"
```

### è°ƒæ•´FP8æ ¼å¼

```yaml
coat:
  optimizer:
    m1_format: "e4m3"  # ä¸€é˜¶åŠ¨é‡: e4m3 (æ¨è) æˆ– e5m2
    m2_format: "e5m2"  # äºŒé˜¶åŠ¨é‡: e4m3 æˆ– e5m2
```

### è‡ªå®šä¹‰é‡åŒ–ç²’åº¦

```yaml
coat:
  activation:
    linear_granularity: "per_tensor"    # per_tensor æˆ– per_group
    nonlinear_granularity: "per_group"  
    group_size: 256                     # å¢å¤§ä»¥å‡å°‘å¼€é”€
```

## 9. å¼•ç”¨

å¦‚æœä½¿ç”¨COATæ–¹æ³•ï¼Œè¯·å¼•ç”¨åŸè®ºæ–‡:
```bibtex
@article{xi2024coat,
  title={COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training},
  author={Xi, Haocheng and Cai, Han and Zhu, Ligeng and Lu, Yao and Keutzer, Kurt and Chen, Jianfei and Han, Song},
  journal={arXiv preprint arXiv:2410.19313},
  year={2024}
}
```
"""
    
    return guide


def main():
    """ä¸»å‡½æ•°"""
    
    print("=" * 60)
    print("COAT + ai-toolkit é›†æˆå·¥å…·")
    print("=" * 60)
    print()
    
    # åˆ›å»ºé›†æˆæŒ‡å—
    guide_path = Path("ai_toolkit_integration/INTEGRATION_GUIDE.md")
    guide_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(guide_path, 'w', encoding='utf-8') as f:
        f.write(create_integration_guide())
    
    print(f"âœ… é›†æˆæŒ‡å—å·²åˆ›å»º: {guide_path}")
    print()
    
    # ç”Ÿæˆè¡¥ä¸æ–‡ä»¶
    optimizer_patch_path = Path("ai_toolkit_integration/patches/optimizer_patch.py")
    optimizer_patch_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(optimizer_patch_path, 'w', encoding='utf-8') as f:
        f.write(patch_ai_toolkit_optimizer())
    
    print(f"âœ… ä¼˜åŒ–å™¨è¡¥ä¸å·²åˆ›å»º: {optimizer_patch_path}")
    
    trainer_patch_path = Path("ai_toolkit_integration/patches/trainer_patch.py")
    with open(trainer_patch_path, 'w', encoding='utf-8') as f:
        f.write(patch_ai_toolkit_trainer())
    
    print(f"âœ… è®­ç»ƒå™¨è¡¥ä¸å·²åˆ›å»º: {trainer_patch_path}")
    print()
    
    print("=" * 60)
    print("ä¸‹ä¸€æ­¥:")
    print("1. é˜…è¯»é›†æˆæŒ‡å—: cat ai_toolkit_integration/INTEGRATION_GUIDE.md")
    print("2. å‡†å¤‡æœè£…æ•°æ®é›†åˆ° datasets/clothing/")
    print("3. æ ¹æ®æŒ‡å—ä¿®æ”¹ai-toolkitä»£ç ")
    print("4. è¿è¡Œè®­ç»ƒ: cd ai-toolkit && python run.py ../ai_toolkit_integration/coat_config.yaml")
    print("=" * 60)


if __name__ == "__main__":
    main()

